{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tropical-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from food_truck_env import FoodTruck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convertible-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, policy):\n",
    "    prob_a = policy[state]\n",
    "    action = np.random.choice(a=list(prob_a.keys()), p=list(prob_a.values()))\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_prediction(env, policy, discount, learning_rate, n_iter):\n",
    "    states = env.state_space\n",
    "    v = {s: 0 for s in states}\n",
    "    \n",
    "    s = env.reset()\n",
    "    for i in range(n_iter):\n",
    "        a = choose_action(s, policy)\n",
    "        s_next, reward, done, _ = env.step(a)\n",
    "        \n",
    "        v[s] += learning_rate * (reward + discount * v[s_next] - v[s])\n",
    "        \n",
    "        if done:\n",
    "            s = env.reset()\n",
    "        else:\n",
    "            s = s_next\n",
    "            \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "systematic-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_policy(states):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        day, inventory = s\n",
    "        prob_a = {}\n",
    "        \n",
    "        if inventory >= 300:\n",
    "            prob_a[0] = 1\n",
    "        else:\n",
    "            prob_a[200 - inventory] = 0.5\n",
    "            prob_a[300 - inventory] = 0.5\n",
    "\n",
    "        policy[s] = prob_a\n",
    "    \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assured-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FoodTruck()\n",
    "policy = some_policy(env.state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "higher-provision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected weekly profit for some policy is:  2499.6345339012455\n"
     ]
    }
   ],
   "source": [
    "v_estimate = td_prediction(env, policy, 1, 0.01, 10 ** 5)\n",
    "print(\"Expected weekly profit for some policy is: \", v_estimate[\"Mon\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-leader",
   "metadata": {},
   "source": [
    "We can see that td prediction also corretly find the weekly profit for this policy. Lets create on-policy TD control method SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unique-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps_greedy(actions, eps, a_best):\n",
    "    \"\"\"\n",
    "    Assigns probability to each action\n",
    "    \n",
    "    If there are 4 actions and eps=0.4, Best action gets 0.7 probability and other actions get 0.1 probability\n",
    "    \"\"\"\n",
    "    prob_a = {}\n",
    "    for a in actions:\n",
    "        if a == a_best:\n",
    "            prob_a[a] = 1 - eps + eps / len(actions)\n",
    "        else:\n",
    "            prob_a[a] = eps / len(actions)\n",
    "            \n",
    "    return prob_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mature-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_policy(states, actions):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        policy[s] = {a: 1 / len(actions) for a in actions}\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "processed-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(env, discount, eps, lr, n_iter):\n",
    "    states = env.state_space\n",
    "    actions = env.action_space\n",
    "    \n",
    "    Q = {s: {a: 0 for a in actions} for s in states}\n",
    "    policy = get_random_policy(states, actions)\n",
    "    \n",
    "    s = env.reset()\n",
    "    a = choose_action(s, policy)\n",
    "    for i in range(n_iter):\n",
    "        if i % 100000 == 0:\n",
    "            print(f\"Iteration: {i}\")\n",
    "        \n",
    "        s_next, reward, done, _ = env.step(a)\n",
    "        a_best = max(Q[s_next], key=Q[s_next].get)\n",
    "        \n",
    "        policy[s_next] = get_eps_greedy(actions, eps, a_best)\n",
    "        a_next = choose_action(s_next, policy)\n",
    "        \n",
    "        Q[s][a] += lr * (reward + discount * Q[s_next][a_next] - Q[s][a])\n",
    "        \n",
    "        if done:\n",
    "            s = env.reset()\n",
    "            a_best = max(Q[s], key=Q[s].get)\n",
    "            policy[s] = get_eps_greedy(actions, eps, a_best)\n",
    "            a = choose_action(s, policy)\n",
    "        else:\n",
    "            s = s_next\n",
    "            a = a_next\n",
    "            \n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developing-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 100000\n",
      "Iteration: 200000\n",
      "Iteration: 300000\n",
      "Iteration: 400000\n",
      "Iteration: 500000\n",
      "Iteration: 600000\n",
      "Iteration: 700000\n",
      "Iteration: 800000\n",
      "Iteration: 900000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Mon', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.92},\n",
       " ('Tue', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.92, 400: 0.02},\n",
       " ('Tue', 100): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.92, 400: 0.02},\n",
       " ('Tue', 200): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Tue', 300): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.92, 400: 0.02},\n",
       " ('Wed', 100): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 200): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 300): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.92, 400: 0.02},\n",
       " ('Thu', 100): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 200): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 300): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 0): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 100): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 200): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 300): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Weekend', 0): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Weekend', 100): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Weekend', 200): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Weekend', 300): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy, Q = sarsa(env, 1, 0.1, 0.05, 1000000)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sapphire-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, discount, eps, lr, n_iter):\n",
    "    states = env.state_space\n",
    "    actions = env.action_space\n",
    "    \n",
    "    Q = {s: {a: 0 for a in actions} for s in states}\n",
    "    policy = get_random_policy(states, actions)\n",
    "    \n",
    "    s = env.reset()\n",
    "    for i in range(n_iter):\n",
    "        if i % 100000 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            \n",
    "        a_best = max(Q[s], key=Q[s].get)\n",
    "        policy[s] = get_eps_greedy(actions, eps, a_best)\n",
    "        a = choose_action(s, policy)\n",
    "        \n",
    "        s_next, reward, done, _ = env.step(a)\n",
    "        Q[s][a] += lr * (reward + discount * max(Q[s_next].values()) - Q[s][a])\n",
    "        \n",
    "        if done:\n",
    "            s = env.reset()\n",
    "        else:\n",
    "            s = s_next\n",
    "            \n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surface-management",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 100000\n",
      "Iteration: 200000\n",
      "Iteration: 300000\n",
      "Iteration: 400000\n",
      "Iteration: 500000\n",
      "Iteration: 600000\n",
      "Iteration: 700000\n",
      "Iteration: 800000\n",
      "Iteration: 900000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Mon', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.92},\n",
       " ('Tue', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.92},\n",
       " ('Tue', 100): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.92, 400: 0.02},\n",
       " ('Tue', 200): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Tue', 300): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.92},\n",
       " ('Wed', 100): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 200): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Wed', 300): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 0): {0: 0.02, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.92},\n",
       " ('Thu', 100): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 200): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Thu', 300): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 0): {0: 0.02, 100: 0.02, 200: 0.92, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 100): {0: 0.02, 100: 0.92, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 200): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Fri', 300): {0: 0.92, 100: 0.02, 200: 0.02, 300: 0.02, 400: 0.02},\n",
       " ('Weekend', 0): {0: 0.2, 100: 0.2, 200: 0.2, 300: 0.2, 400: 0.2},\n",
       " ('Weekend', 100): {0: 0.2, 100: 0.2, 200: 0.2, 300: 0.2, 400: 0.2},\n",
       " ('Weekend', 200): {0: 0.2, 100: 0.2, 200: 0.2, 300: 0.2, 400: 0.2},\n",
       " ('Weekend', 300): {0: 0.2, 100: 0.2, 200: 0.2, 300: 0.2, 400: 0.2}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy, Q = q_learning(env, 1, 0.1, 0.01, 1000000)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-mineral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
